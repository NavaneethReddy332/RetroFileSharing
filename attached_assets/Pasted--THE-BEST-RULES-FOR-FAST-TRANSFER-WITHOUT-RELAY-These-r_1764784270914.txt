‚ö° THE BEST RULES FOR FAST TRANSFER WITHOUT RELAY

These rules are what Snapdrop / Airdrop / SendAnywhere P2P direct mode follow.

‚úÖ RULE 1 ‚Äî USE WEBRTC DATA CHANNEL FOR PURE P2P UDP TRANSFER

WebRTC uses UDP, not TCP.

UDP = faster than HTTP / XMLHttpRequest.

Only WebRTC can transfer at near maximum network speed directly between devices.

Not WebSockets.
Not AJAX.
Not fetch().
Only WebRTC Data Channel.

‚úÖ RULE 2 ‚Äî ALWAYS TRY DIRECT CONNECTION FIRST

Before transfer, exchange:

üîπ WebRTC offer
üîπ ICE candidates

Use a STUN server to get real public IP & NAT port mapping.

Use public STUN service, e.g.:

stun:stun.l.google.com:19302
stun:stun1.l.google.com:19302


When direct connection is possible (same LAN or successful NAT hole punch), speed is near user‚Äôs max.

‚úÖ RULE 3 ‚Äî DO NOT SPLIT INTO LARGE CHUNKS

Many tutorials say ‚Äúchunk size 64KB‚Äù or ‚Äú512KB‚Äù.

For maximum speed:

‚úî Use CHUNKS = ~16KB to 64KB
‚úî Too small = overhead.
‚úî Too large = buffer pressure, throttles.

Optimal chunk size = 32KB for most networks.

‚úÖ RULE 4 ‚Äî PIPE DATA IN A CONTINUOUS STREAM

Do NOT send one chunk, wait for ack, then send next.

Instead:

while(buffer_has_data AND peer_buffer_not_full){
    dataChannel.send(next32KBchunk);
}


This ensures maximum pipeline utilization.

‚úÖ RULE 5 ‚Äî NEVER BLOCK THE SEND LOOP

Do NOT use:

await dataChannel.send(chunk);


Instead use a send buffer queue.

Push chunks like:

if(dataChannel.bufferedAmount < MAX_BUFFER_LIMIT){
    dataChannel.send(chunk);
}


And monitor:

dataChannel.onbufferedamountlow = () => {
   // send more
}


This ensures the channel is always ‚Äúfull but not overloaded‚Äù.

‚úÖ RULE 6 ‚Äî TUNE BUFFER

WebRTC buffer defaults vary by browser.

For fastest transfers:

const MAX_BUFFER_LIMIT = 16 * 1024 * 1024; // 16 MB of buffer


Keep buffer full but never overflow.

‚úÖ RULE 7 ‚Äî SIGNAL ONLY ONCE, THEN TRANSFER

Your signaling server should do ONLY:

‚úî exchange WebRTC SDP offer
‚úî exchange ICE candidates

After this, remote peer sends back ready ‚Üí then start streaming.

No repeated server pings. No repeated signaling.

‚úÖ RULE 8 ‚Äî USE BINARY TRANSFER (ARRAYBUFFER), NOT STRING

Do NOT convert chunks to Base64 or JSON.

Do NOT send text.

‚úî Use event.dataChannel.send(arrayBuffer) (binary only)

Binary = native speed.
Text = slow & inefficient.

‚úÖ RULE 9 ‚Äî OPTIMIZE FILE READING

FileReader/File slicing:

Use:

const CHUNK_SIZE = 32 * 1024; // 32 KB


And read like:

function sendNextChunk(){
   const chunk = file.slice(offset, offset + CHUNK_SIZE);
   fileReader.readAsArrayBuffer(chunk);
}


Stop only when buffer is near full.
Do NOT read entire file in memory.

‚úÖ RULE 10 ‚Äî USE BACKPRESSURE CONTROL

Only send more if:

dataChannel.bufferedAmount < MAX_BUFFER_LIMIT/2


This ensures:

‚úî buffer is full
‚úî channel is fast
‚úî no stalls or crashes

‚úÖ RULE 11 ‚Äî PREFER LOSSY NETWORK (UDP) OVER RELIABLE

WebRTC default is reliable mode, which ensures delivery but reduces speed.

If you want MAX SPEED, configure DataChannel:

pc.createDataChannel('file', {
    ordered: true,          // keep order
    maxRetransmits: 0       // 0 = no retransmission = faster 
});


This sacrifices retransmit but doubles speed.

‚ö† Only do this if app CAN handle occasional missing packets.
Most file transfers can handle small retransmission at the application level.

‚úÖ RULE 12 ‚Äî CORRECT CHUNK WINDOW MANAGEMENT (KEY)

Do not wait for each chunk.
Never use:

for(each chunk) {
    await send(chunk); // BAD!
}


Use a window of multiple chunks like:

send next chunk ONLY WHEN buffer < threshold


This keeps the pipeline full.

‚úÖ RULE 13 ‚Äî TURN OFF UNNECESSARY LOGGING

Frequent console logs kill speed.

Remove:

console.log(chunk);


Speed drops drastically.

‚úÖ RULE 14 ‚Äî FOR SAME-NETWORK TRANSFERS (LAN), FORCE ICE TO PREFER LOCAL

Use:

pcConfig = {
  iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
  iceCandidatePoolSize: 10,
};


Allows best NAT hole punching ‚Üí max speed.

‚úÖ RULE 15 ‚Äî HANDLE WI-FI SCHEDULER & POWER SAVE

Mobile or laptops sometimes throttle network on battery save.

üëâ Hold network alive
üëâ Disable sleep timers while transfer

(This is app-level optimization.)

‚úÖ RULE 16 ‚Äî MEASURE REAL-TIME SPEED

Do not measure speed after everything.

Measure speed like:

deltaBytes / deltaTime


Every 500 ms.

This gives fast live UI.

‚úÖ FINAL SPEED REALITY CHECK (Browser WebRTC Limits)
Conditions	Expected Speed
Same WiFi, perfect hole punch	20‚Äì60 Mbps (40 avg)
Same LAN (best case)	40‚Äì150 Mbps
Different networks (public Internet)	10‚Äì30 Mbps (norm)
One user on mobile, one on laptop	5‚Äì25 Mbps

Browser P2P will never fully match server upload/download of ~150 Mbps, specially on cheap notebooks & WiFi.

‚ö° SPECIAL ADVANCED OPTION (USE MULTIPLE DATA CHANNELS AT ONCE)

To approach 100+ Mbps, like SendAnywhere:

Instead of 1 single channel:

Create multiple parallel data channels (like 4‚Äì6).

for(let i=0; i<4; i++){
  channels[i] = pc.createDataChannel(`file-${i}`, {
    ordered: false,  // fastest
    maxRetransmits: 0 
  });
}


Send different chunk windows on each channel simultaneously.

This increases throughput ~3‚Äì5√ó.

‚úÖ PERFECT RULES SUMMARY (ALL)
RULE	PURPOSE
1	Use WebRTC (UDP P2P), not HTTP fetch
2	Try DIRECT connection FIRST (STUN hole punch)
3	Use 32KB chunk size (optimum)
4	Keep pipeline full (send continuously)
5	Use bufferedAmount + low buffer events
6	Set max buffer ~16 MB
7	Only signal once; no repeated server calls
8	Send binary (ArrayBuffer), not text
9	Read file in sliding window slices
10	Respect backpressure & buffer limits
11	Use ‚ÄúmaxRetransmits = 0‚Äù for fastest UDP mode
12	Manage chunk window, do not await sends
13	Turn off logging during transfer
14	Prefer local ICE route if same network
15	Optional: multiple parallel data channels
16	Measure speed every 0.5‚Äì1s for UI updates
üî• FINAL ONE-LINE ANSWER YOU CAN COPY

‚ÄúTo achieve lightning-fast P2P transfer without any relay, use WebRTC UDP data channels with a properly filled, continuous stream (32KB chunks, binary transfer, no awaiting send calls), saturate the pipeline by monitoring bufferedAmount, and optionally use multiple parallel channels for max throughput.‚Äù